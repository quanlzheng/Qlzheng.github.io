<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Distraction-aware Shadow Detection</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="">
<meta name="keywords" content="Shadow; Detection;">
<meta name="keywords" content="Quanlong Zheng; 郑全龙; Computer Vision;">
<link rel="author" href="https://quanlzheng.github.io/">

<!-- Fonts and stuff -->
<link href="./css/css" rel="styles<!-- heet" type="text/css">
<link rel="stylesheet" type="text/css" href="./css/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./css/iconize.css">
<script async="" src="./css/prettify.js.download"></script>
 

</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1>Distraction-aware Shadow Detection</h1>

	<div class="authors">
	  <a href="https://quanlzheng.github.io/">Quanlong Zheng</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://xtqiao.com/">Xiaotian Qiao</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://www.ying-cao.com/">Ying Cao</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson Lau</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	</div>

	<div class="affiliations">

	  <p>City University of Hong Kong</p>
	</div class='section teaser'>

	<!-- <div class="venue">Preprint Manuscript (<a href="https://arxiv.org/" target="_blank">Arxiv</a>) 2018</div> -->
      </div>
      
      <center><img src="./Distraction-aware-Shadow-Detection/teaser.png" border="0" width="90%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>
Shadow detection is an important and challenging task for scene understanding. Despite promising results from recent deep learning based methods. Existing works still struggle with ambiguous cases where the visual appearances of shadow and non-shadow regions are similar (referred to as distraction in our context). In this paper, we propose a Distraction-aware Shadow Detection Network (DSDNet) by explicitly learning and integrating the semantics
of visual distraction regions in an end-to-end framework. At the core of our framework is a novel standalone, differentiable distraction-aware module, which allows us to learn distraction-aware, discriminative features for robust shadow detection. Our proposed module learns to extract and fuse distraction-indicative features into the visual features of the input image, by explicitly predicting false positives and false negatives. We conduct extensive experiments on three public shadow detection datasets, SBU, UCF and ISTD, to evaluate our method. Experimental results demonstrate that our model can boost shadow detection performance, by effectively suppressing the detection of false positives and false negatives, achieving state-of-the-art results.
	</p>
      </div>


      


<div class="section architecture">
	<h2>Architecture</h2>
	<br>
	<center><img src="./Distraction-aware-Shadow-Detection/Architecture.png" border="0" width="90%"></center>
</div>


<div class="section architecture">
	<h2>DS Module</h2>
	<br>
	<center><img src="./Distraction-aware-Shadow-Detection/DS-module.png" border="0" width="90%"></center>
</div>





<div class="section download">

	<h2>Downloads</h2>
<!-- <HR size=2> -->

<ul>
	<li>
		  <a href="./Distraction-aware-Shadow-Detection/3109.pdf" target="_blank">Paper</a>
	</li>
	<li>
		  <a href="./Distraction-aware-Shadow-Detection/3109-supp.pdf" target="_blank">Supp.</a>
	</li>

	<li>
		  <a href="./Distraction-aware-Shadow-Detection/Poster_shadow_2019.pdf" target="_blank">Poster</a>
	</li>

	<li>
		  <a href="https://drive.google.com/open?id=1cQD7kdwfnP5HhSAhk-rSjayKz7i2t0Tq" target="_blank">Results</a>
	</li>
	<li>
		  <a href="https://drive.google.com/open?id=18hv6NAQsST1UsabtNvfM_G-qR-nAbgaa" target="_blank">Codes</a>
	</li>
	<li>
		  <a href="https://drive.google.com/open?id=1-YnAGDzn5GqYfZDLZ4NHZy-TWstwFg_S" target="_blank">Models</a>
	</li>
	<li>
		  <a href="https://drive.google.com/open?id=1gwfGXZB5yiEsg_iiVQ94tNy2ReFnlUTs" target="_blank">Distraction Dataset</a>
	</li>





<!-- 	<li>
		  <a href="" target="_blank">Model (Coming soon)</a>
	</li> -->

		<!-- <li>
		  <a href="" target="_blank">Result (Coming soon)</a>
	</li>
	<li>
		  <a href="" target="_blank">Poster (Coming soon)</a>
	</li> -->


</ul>
</div>








<br>

<div class="section citation">

	<h2>Citation</h2>
	<div class="section bibtex">
	  <pre>@InProceedings{Zheng_2019_CVPR,
	author = {Zheng, Quanlong and Qiao, Xiaotian and Cao, Ying and Lau, Rynson W.H.},
	title = {Distraction-Aware Shadow Detection},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2019}
}
	  </pre>
	  </div>
      </div>

</div></div></body></html>